{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vergleich"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell SAM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vergleich zu anderen Modellen -> vergleich_bing.txt <br>\n",
    "Tabelle? -> https://jupyterbook.org/en/stable/reference/cheatsheet.html#tables \n",
    "\n",
    "Unterschiede:\n",
    "- Architektur: Transformer vs CNN\n",
    "- Transfer: Zero Shot vs Supervised\n",
    "- Stages: One-Stage vs Two-Stage\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vergleich mit anderen Algorithmen für medizinische Bilder {cite}`he2023computervision`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensatz SA-1B\n",
    "\n",
    "**Andere bekannte Datasets für Segmentation Tasks:**\n",
    "- LVIS v1\n",
    "- COCO\n",
    "- ADE20K\n",
    "- Open Images\n",
    "\n",
    "```{figure} ./images/vergleich_dataset.png\n",
    ":name: vergleich_dataset\n",
    ":align: center\n",
    "Vergleich mit anderen populären Datasets für Image Segmentation. {cite}`kirillov2023segment`.\n",
    "```\n",
    "\n",
    "**&rarr; Vorteile von SAM**\n",
    "- SA-1B deckt **Bildecken** besser ab als andere\n",
    "- hat **11x mehr Bilder** und **400x mehr Masken**\n",
    "- **diversere** Masken"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualität der Masken\n",
    "**&rarr; IoU Vergleich** mit Paar von automatisch erkannten und professionell annotierten Masken \n",
    "\n",
    "- SAM &rarr; 94% der Paare haben höher als 90% IoU\n",
    "- LVIS &rarr; vorherige Arbeiten haben nur 85-91% IoU\n",
    "\n",
    "```{figure} ./images/vergleich_lvis.png\n",
    ":name: vergleich_lvis\n",
    ":align: center\n",
    "Vergleich mit Zero-Shot-Instanzsegmentierung auf LVIS v1. {cite}`kirillov2023segment`.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zentren der Masken\n",
    "\n",
    "**&rarr; räumliche Verteilung der Objekt Zentren im Vergleich**\n",
    "\n",
    "```{figure} ./images/vergleich_dataset_center.png\n",
    ":name: vergleich_dataset_center\n",
    ":align: center\n",
    "Vergleich von SAM anhand der Bildgröße normierter Verteilungen der Maskenzentren. {cite}`kirillov2023segment`.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Responsible AI - Repräsentation \n",
    "\n",
    "**&rarr; Vergleich von Geographie- und Einkommens-Repräsentation im Dataset**\n",
    "\n",
    "```{figure} ./images/vergleich_dataset_geo.png\n",
    ":name: vergleich_dataset_geo\n",
    ":width: 400px\n",
    "height: 300px\n",
    ":align: center\n",
    "Vergleich von SAM anhand der Responsible AI Repräsentationen. {cite}`kirillov2023segment`.\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorteile\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nachteile"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
