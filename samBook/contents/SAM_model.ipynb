{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Komponenten\n",
    "\n",
    "```{figure} ./images/model_aufbau.png\n",
    ":name: model_aufbau\n",
    ":align: center\n",
    "Komponenten des Segment Anything Models. Image Encoder, Prompt Encoder, and Mask Decoder. {cite}`kirillov2023segment`\n",
    "```\n",
    "\n",
    "### 1. Image Encoder\n",
    "- Erstellt **Image Embeddings** für Input-Bilder\n",
    "- In Theorie kann jede Art von Image Encoder verwendet werden\n",
    "    - Vorausgesetzt Output ist ein (C×H×W) Embedding\n",
    "- **Vision Transformer** (ViT) von {site} `dosovitskiy2021image`. Angepasst für hochauflösende Input Bilder\n",
    "    - pre-trained mit **Masked Autoencoder** (MAE) Verfahren\n",
    "    - ViT-H/16\n",
    "    - 14x14 windowed attention Blocks\n",
    "    - 4 global attention Blocks\n",
    "\n",
    "```{figure} ./images/ImageEncoderDiagram.png\n",
    ":name: ImageEncoderDiagram\n",
    ":align: center\n",
    "SAM Image Decoder Struktur im Detail. {cite}`kirillov2023segment`\n",
    "```\n",
    "\n",
    "### 2. Prompt Encoder\n",
    "- Prompts werden je nach Art unterschiedlich encoded\n",
    "\n",
    "| Type   | Prompt | Embedding                                  |\n",
    "|--------|--------|--------------------------------------------|\n",
    "| Sparse | Points | Positional Encoding + gelernte Embeddings |\n",
    "| Sparse | Boxes  | Positional Encoding + gelernte Embeddings |\n",
    "| Sparse | Text   | CLIP Encoder                               |\n",
    "| Dense  | Mask   | Convolution Embedding + Image Embedding    |\n",
    "\n",
    "- Sparse Prompts werden auf ein **256-dimensional vectorial Embedding** gemappt:\n",
    "    - **Points:** Positional Encodings der Koordinaten summiert mit trainierten Embeddings für Forder- bzw. Hintergrund.\n",
    "    - **Box:** Embedding Paar: Positional Encoding von Koordinaten \"Oben Links\" und \"Unten Rechts\" werden mit zugehörigen gelernten Embeddings summiert.\n",
    "    - **Text:** CLIP Encoder. Jedoch jeder Text Encoder theoretisch möglich.\n",
    "- **Masks** (Dense Prompts) werden gedownscaled und durch mehrere Convolution Layers transformiert (Siehe Abbildung xx).\n",
    " \n",
    "```{figure} ./images/MaskPromptEncoding.png\n",
    ":name: MaskPromptEncoder\n",
    ":align: center\n",
    "SAM Mask Prompt Encoding Struktur. {cite}`kirillov2023segment`\n",
    "```\n",
    "\n",
    "\n",
    "### 3. Mask Decoder\n",
    "- Mappt Image Encoding, Prompt Encoding und ein Output Token auf eine Mask\n",
    "    - Vor Decoding wird dem Prompt Embedding ein trainiertes **Output Token Embedding** hinzugefügt.\n",
    "- Modifizierter **Transformer Decoder Block** gefolgt von einem **Dynamic Mask Prediction Head**\n",
    " \n",
    "- Inspiriert von Transformer Architekturen von {site} `carion2020endtoend` und {site} `cheng2021perpixel`\n",
    "\n",
    "```{figure} ./images/mask_decoder_model.png\n",
    ":name: mask_decoder_model\n",
    ":align: center\n",
    "SAM Mask Decoder. {cite}`kirillov2023segment`\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "- Nutzung eines **Interactive Segmentation Setup** angelehnt an {cite}`sofiiuk2021reviving` und {cite}`forte2020getting`.\n",
    "- 11 Interationen pro Trainingsschritt:\n",
    "    - Erste Prediction mit Bounding Box oder Point Prompt\n",
    "    - 8 Iterative Predictions mit Vorheriger Output Maske und gesampelten Punkten der Prediction Error Region\n",
    "    - Zwei zusätzliche Iterationen ohne zusätzliche Punkte (Nur vorherige Output Maske)\n",
    "    \n",
    "- Durch die gute Performance des Decoders können deutlich mehr Iterationen pro Trainingsschritt als in vorherigen Intractive Segmentation Projekten verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
