{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Komponenten\n",
    "\n",
    "```\n",
    "{figure} ./images/model_aufbau.png\n",
    ":name: model_aufbau\n",
    ":align: center\n",
    "Komponenten des Segment Anything Models. Image Encoder, Prompt Encoder, and Mask Decoder. {cite}`kirillov2023segment`\n",
    "```\n",
    "\n",
    "### 1. Image Encoder:\n",
    "- Erstellt **Image Embeddings** für Input-Bilder\n",
    "- **Vision Transformer** (ViT) von {site} `dosovitskiy2021image`. Angepasst für hochauflösende Input Bilder\n",
    "    - ViT-H/16\n",
    "    - 14x14 windowed attention Blocks\n",
    "    - 4 global attention Blocks\n",
    "- pre-trained mit einem **Masked Autoencoder** (MAE)\n",
    "\n",
    "```\n",
    "{figure} ./images/ImageEncoderDiagram.png\n",
    ":name: ImageEncoderDiagram\n",
    ":align: center\n",
    "SAM Image Decoder Struktur im Detail. {cite}`kirillov2023segment`\n",
    "```\n",
    "\n",
    "### 2. Prompt Encoder:\n",
    "- Prompts werden je nach Art unterschiedlich encoded\n",
    "\n",
    "| Type   | Prompt | Encoding                                              |\n",
    "|--------|--------|-------------------------------------------------------|\n",
    "| Sparse | Points | Positional Encoding summiert mit gelernten Embeddings |\n",
    "| Sparse | Boxes  | Positional Encoding summiert mit gelernten Embeddings |\n",
    "| Sparse | Text   | CLIP Encoder                                          |\n",
    "| Dense  | Mask   | Convolution Embedding summiert mit Image Embedding    |\n",
    "\n",
    "- Sparse Prompts werden auf ein **256-dimensionales vectorial Embedding** gemappt\n",
    "    - **Points:** Sum of a positional encoding of the point’s location and one of two learned embeddings(foreground or background).\n",
    "    - **Box:** Embedding Paar: Positional Encoding von Koordinaten \"Oben Links\" werden mit gelerntem Embedding für \"Oben Links\" summiert. Koordinaten für \"Unten Rechts\" werden identisch mit eigenem Embeddings summiert.\n",
    "    - **Text:** CLIP Encoder. Jedoch jeder Text Encoder teoretisch möglich.\n",
    "- Dense Prompts (Masks):\n",
    "    - Masken werden gedownscaled und durch mehrere Convolution Layers transformiert (Siehe Bild).\n",
    " \n",
    "```\n",
    "{figure} ./images/MaskPromptEncoder.png\n",
    ":name: MaskPromptEncoder\n",
    ":align: center\n",
    "SAM Mask Prompt Encoding Struktur. {cite}`kirillov2023segment`\n",
    "```\n",
    "\n",
    "\n",
    "### 3. Mask Decoder:\n",
    "- Mappt Image Encoding, Prompt Encoding und ein Output Token auf eine Mask\n",
    "- Modifizierter **Transformer Decoder Block** gefolgt von einem **Dynamic Mask Prediction Head**\n",
    "- Inspiriert von {site} `carion2020endtoend` und {site} `cheng2021perpixel`\n",
    "\n",
    "```\n",
    "{figure} ./images/mask_decoder_model.png\n",
    ":name: mask_decoder_model\n",
    ":align: center\n",
    "SAM Mask Decoder. {cite}`kirillov2023segment`\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
