---
---

@misc{kirillov2023segment,
      title={Segment Anything}, 
      author={Alexander Kirillov and Eric Mintun and Nikhila Ravi and Hanzi Mao and Chloe Rolland and Laura Gustafson and Tete Xiao and Spencer Whitehead and Alexander C. Berg and Wan-Yen Lo and Piotr Dollár and Ross Girshick},
      year={2023},
      eprint={2304.02643},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{bommasani2022opportunities,
      title={On the Opportunities and Risks of Foundation Models}, 
      author={Rishi Bommasani and Drew A. Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S. Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E. Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D. Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher Ré and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W. Thomas and Florian Tramèr and Rose E. Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang},
      year={2022},
      eprint={2108.07258},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{dosovitskiy2021image,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{carion2020endtoend,
      title={End-to-End Object Detection with Transformers}, 
      author={Nicolas Carion and Francisco Massa and Gabriel Synnaeve and Nicolas Usunier and Alexander Kirillov and Sergey Zagoruyko},
      year={2020},
      eprint={2005.12872},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{cheng2021perpixel,
      title={Per-Pixel Classification is Not All You Need for Semantic Segmentation}, 
      author={Bowen Cheng and Alexander G. Schwing and Alexander Kirillov},
      year={2021},
      eprint={2107.06278},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{chen2022focalclick,
      title={FocalClick: Towards Practical Interactive Image Segmentation}, 
      author={Xi Chen and Zhiyan Zhao and Yilei Zhang and Manni Duan and Donglian Qi and Hengshuang Zhao},
      year={2022},
      eprint={2204.02574},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{AI_2023, 
      title={Segment anything}, 
      url={https://segment-anything.com/}, 
      journal={Segment Anything}, 
      publisher={Meta AI}, 
      author={AI, Meta}, 
      year={2023}
} 

@misc{he2023computervision,
      title={Computer-Vision Benchmark Segment-Anything Model (SAM) in Medical Images: Accuracy in 12 Datasets}, 
      author={Sheng He and Rina Bao and Jingpeng Li and Jeffrey Stout and Atle Bjornerud and P. Ellen Grant and Yangming Ou},
      year={2023},
      eprint={2304.09324},
      archivePrefix={arXiv},
      primaryClass={eess.IV}
}

@misc{Polat_2023, 
      title={Grounding-dino + segment anything model (SAM) vs mask-RCNN: A Comparison}, 
      url={https://encord.com/blog/grounding-dino-sam-vs-mask-rcnn-comparison/}, 
      journal={Comparing Grounding-DINO + Segment Anything Model (SAM) vs Mask-RCNN}, 
      author={Polat, Görkem}, 
      year={2023}, 
      month={Apr}
} 

@INPROCEEDINGS{9722616,
  author={Ghafari, Mehran and Mailman, Daniel and Hatami, Parisa and Peyton, Trevor and Yang, Li and Dang, Weiwei and Qin, Hong},
  booktitle={2022 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={A Comparison of YOLO and Mask-RCNN for Detecting Cells from Microfluidic Images}, 
  year={2022},
  volume={},
  number={},
  pages={204-209},
  doi={10.1109/ICAIIC54071.2022.9722616}
}

@misc{zou2023segment,
      title={Segment Everything Everywhere All at Once}, 
      author={Xueyan Zou and Jianwei Yang and Hao Zhang and Feng Li and Linjie Li and Jianfeng Gao and Yong Jae Lee},
      year={2023},
      eprint={2304.06718},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{UX-Decoder_2023, 
      title={UX-Decoder/segment-everything-everywhere-all-at-once: Official implementation of the paper “Segment everything everywhere all at once”}, 
      url={https://github.com/ux-decoder/segment-everything-everywhere-all-at-once}, 
      journal={SEEM: Segment Everything Everywhere All at Once}, 
      publisher={GitHub}, 
      author={UX-Decoder}, 
      year={2023}
} 